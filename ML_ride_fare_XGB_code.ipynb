{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try classification with XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[1, 2, 3, 4, 5, 6]\n",
      "17176\n",
      "<class 'numpy.ndarray'>\n",
      "103056\n",
      "17176\n",
      "<class 'numpy.ndarray'>\n",
      "17176\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# First XGBoost model for Pima Indians dataset\n",
    "from numpy import loadtxt\n",
    "#from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "range1 = [i for i in range(1, 7)]\n",
    "#range2 = [i for i in range(9,9)]\n",
    "# range3 = [i for i in range(6,7)]\n",
    "# range4 = [i for i in range(11,13)]\n",
    "# range5 = [i for i in range(14,26)]\n",
    "# range6 = [i for i in range(29,31)]\n",
    "# range7 = [i for i in range(32,35)]\n",
    "#depth 6 above 22\n",
    "\n",
    "# #depth7\n",
    "# range8=[ 2, 8, 27,35] \n",
    "# range9=[ 5, 9, 26, 28] #9, 5, 26, 28\n",
    "# range10=[10,4]\n",
    "\n",
    "usecols = range1  # range2 + range3 + range4 + range5 + range6 + range7 + range8 + range9\n",
    "\n",
    "#28\n",
    "#usecols=[17, 19, 30, 5, 18, 20, 31, 34, 1, 25, 14, 26, 7, 33, 9, 29, 13, 21, 4, 22, 32, 24, 6, 23, 2, 16, 8, 12]\n",
    "#usecols=[17, 19, 30, 5, 18, 20, 31, 34, 1, 25, 14, 26, 7, 33, 9, 29, 13, 21, 4]\n",
    "\n",
    "\n",
    "print(len(usecols))\n",
    "print(usecols)\n",
    "\n",
    "# load data\n",
    "dataset = loadtxt(\"train.csv\", delimiter=',', skiprows=1, usecols=usecols) #usecols=range(0,36)\n",
    "#testset2 = pd.read_csv(\"test.csv\")\n",
    "#dataset = loadtxt(strip_first_col('cse_DS_Intro3TRAIN.csv'), delimiter=\",\")\n",
    "#dataset = loadtxt('cse_DS_Intro3TRAIN.csv', delimiter=\",\")\n",
    "testset = loadtxt(\"test.csv\", delimiter=',', skiprows=1, usecols=usecols)\n",
    "\n",
    "#print(testset)\n",
    "# split data into X and y\n",
    "X = dataset[:,0:]\n",
    "print(len(X))\n",
    "print(type(X))\n",
    "print(X.size)\n",
    "\n",
    "Y = loadtxt(\"train.csv\", delimiter=',', skiprows=1, usecols=range(7,8))\n",
    "print(len(Y))\n",
    "print(type(Y))\n",
    "print(Y.size)\n",
    "\n",
    "#print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72138\n",
      "12023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.316%\n",
      "{'colsample_bytree': 0.8, 'gamma': 4.0, 'learning_rate': 0.22, 'max_depth': 6, 'subsample': 0.8}\n",
      "Accuracy score: 95.01%\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test sets\n",
    "seed = 9 #96.808 2 3-96.923:93.74 96.929:94.13-9 Accuracy: 96.957% \n",
    "\n",
    "test_size_ = 0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size_, random_state=seed)\n",
    "\n",
    "print(X_train.size)\n",
    "print(y_train.size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "parameters = {\n",
    "     #\"eta\"    : [0.01] ,\n",
    "     'learning_rate':[ 0.22], #Accuracy: 95.812% 0.1 95.962 .22 96.697 Accuracy: 97.031% Accuracy: 97.051%\n",
    "\n",
    "\n",
    "\n",
    "     \"max_depth\"        : [6],\n",
    "     #\"min_child_weight\" : [10],\n",
    "     \"gamma\"            : [ 4.0],\n",
    "     \"colsample_bytree\" : [ 0.8], #96.818 96.863\n",
    "     #\"num_class\": [2],\n",
    "     #\"objective\": ['multi:softmax'],\n",
    "     \"subsample\":[0.8],\n",
    "     #'n_estimators':[100] #929\n",
    "     }\n",
    "\n",
    "\n",
    "grid = GridSearchCV(clf,\n",
    "                    parameters, n_jobs=14,  scoring=\"f1\")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Accuracy: %.3f%%\" % (grid.best_score_ * 100.0))\n",
    "print(grid.best_params_)\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy score: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#test_X = test[predictor_cols]\n",
    "# Use the model to make predictions\n",
    "classes = grid.predict(testset)\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "# print(classes)\n",
    "\n",
    "testset2 = pd.read_csv(\"orig/test.csv\")\n",
    "\n",
    "my_submission = pd.DataFrame({'tripid': testset2.tripid, 'prediction': classes})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('sub/6.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    8200\n",
      "0.0     376\n",
      "Name: prediction, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sub/5.csv'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tmp=pd.read_csv('5.csv')\n",
    "print(sample_tmp['prediction'].value_counts())\n",
    "\n",
    "from shutil import copyfile\n",
    "copyfile('5.csv', 'sub/5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv(\"sub/6.csv\")\n",
    "print(type(sub['prediction'][0]))\n",
    "sub['prediction'].replace(to_replace=[1.0, 0.0], value=[1,0], inplace=True)\n",
    "\n",
    "sub.to_csv('sub/5.csv', sep=',', encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
